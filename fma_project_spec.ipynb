{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Project info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Project title**: Kick out the jams: Classifying song genres\n",
    "\n",
    "**Name:** Lina Tran, Joel Ostblom, Madeleine Bonsma-Fisher, Ahmed Hasan\n",
    "\n",
    "**E-mail:** lina.mntran@gmail.com, joel.ostblom@gmail.com, m.bonsma@mail.utoronto.ca, ahmed.hasan@mail.utoronto.ca\n",
    "\n",
    "**GitHub username**: linanmt, joelostblom, mbonsma, aays\n",
    "\n",
    "**Link to prior writing**: [Lina](https://github.com/UofTCoders/studyGroup/blob/gh-pages/lessons/python/classes/Classes_in_Python.ipynb), [Joel](https://github.com/UofTCoders/rcourse/blob/master/lec02-basic-r.Rmd), [Madeleine](https://github.com/UofTCoders/rcourse/blob/master/lec07-pop-models.Rmd), [Ahmed](https://github.com/UofTCoders/studyGroup/blob/gh-pages/lessons/r/dplyrmagrittr/lesson.Rmd) \n",
    "\n",
    "**Short description**: A short description of the project, less than 110 characters. This will be read by the students on the DataCamp platform **before** deciding to start the project.\n",
    "\n",
    "> Using a dataset of song properties, apply machine learning methods in Python to classify tracks by genre.\n",
    "\n",
    "---\n",
    "\n",
    "#### Long description ####\n",
    "\n",
    "A longer description of the project, around four sentences in length. \n",
    "This will be read by the students on the DataCamp platform **before** deciding to start the project.\n",
    "\n",
    "It should mention some of the major prerequisites for completing the project \n",
    "(for example \"familiarity with `pandas` DataFrames\" or \"know how to use the Naive Bayes method from `scikit learn`\")\n",
    "\n",
    "> Using a subset of the dataset comprised of two genres (Hip-Hop and Rock), we will train a classifier to distinguish between the two genres based only on track information derived from Echonest (now part of Spotify) data for each track. We will first make use of `pandas` and `seaborn` packages in Python for subsetting the data, aggregating information, and creating plots when exploring the data for obvious trends or factors we should be aware of when doing machine learning. Next, we will use of the `scikit-learn` package to predict whether we can correctly classify a song's genre based on features such as danceability, energy, acousticness, tempo etc. We will go over implementations of common algorithms such as PCA, logistic regression, decision trees and so forth.\n",
    "\n",
    "\n",
    "#### Datasets used ####\n",
    "\n",
    "Short description (and ideally links) to the datasets used in the project. This will be read my me (David) only.\n",
    "\n",
    "> An open dataset for music analysis - https://github.com/mdeff/fma. The tracks represented in the dataset are all from the Free Music Archive, a large library of free audio downloads. \n",
    "\n",
    "> https://www.dropbox.com/sh/bab3yu27thfcv45/AAAHoBux36O54Dyg6UUOBv_8a?dl=0\n",
    "\n",
    "#### Assumed student background ####\n",
    "\n",
    "What background knowledge you assume the student doing this project will have. The more specific the better. This will be read my me (David) only. Please list things like modules, tools, functions, methods, and statistical concepts and jargon.\n",
    "\n",
    "Not so useful: \"The student has a basic familiarity with `pandas`.\"\n",
    "\n",
    "More useful: \"The student knows how to read in a csv file using `pandas` and how to compute grouped summary statistics using `groupby()`.\"\n",
    "\n",
    "> The student knows how to read in csv and json files using `pandas`, and examine correlations across the columns of a `pandas` DataFrame. The student understands basic plotting (scatter plots, pair plots) with `seaborn`. The student is also familiar with implementing principal component analysis, supervised learning methods (decision trees and logistic regression), and model accuracy scoring using k-fold crossvalidation and the classification report in scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Project narrative intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## These recommendations are so on point! How does this playlist know me so well?\n",
    "\n",
    "> Over the past few years, streaming services with vast catalogues have increasingly become the primary means through which most people listen to their favourite music. But at the same time, the wealth of options on offer can mean users might be a bit overwhelmed when trying to look for newer music that suits their tastes. \n",
    "\n",
    "> For this reason, streaming services have found various means of categorizing music to allow for personalized recommendations. One method involves direct analysis of the raw audio information in a given song, scoring the raw data on a variety of metrics. Today, we'll be examining data compiled by a research group known as The Echo Nest. Our goal is to look through this dataset and classify songs as being either 'Hip-Hop' or 'Rock' - all without listening to a single one ourselves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> To begin with, let's load the data on our tracks alongside the track metrics compiled by The Echo Nest. These exist in two different files, which are in different formats - `csv` and `json`. While `csv` is a popular file format for denoting tabular data, `json` is another common file format in which databases often return the results a given query. \n",
    "\n",
    "> Let's start by creating two `pandas` DataFrames out of these files, and then merging the DataFrames into one for our genre classification analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tracks = pd.read_csv('./fma-rock-vs-hiphop.csv')\n",
    "tracks.info()\n",
    "track_metrics = pd.read_json('./echonest-clean.json')\n",
    "track_metrics.info()\n",
    "\n",
    "# Students will remove NAs here\n",
    "\n",
    "echo_tracks = pd.merge(track_metrics, tracks[['genre_top', 'title', 'track_id']], on='track_id')\n",
    "echo_tracks.head()\n",
    "\n",
    "# Students will make a correlation matrix to explore if there are correlated variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. PCA and visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The variance between genres could possibly be explained by just a few variables in the data set. To identify these, a commonly used dimensionality reduction approach is Principal Component Analysis (PCA), which rotates the data along the axis of highest variance and allows for visualization in lower dimensions.\n",
    "\n",
    "> First, we will preprocess the data by assigning all numerical features into the features variable and the genres into the labels variable.\n",
    "\n",
    "> Next, we will use PCA to find out the intrinsic number of dimensions for the data, and visualize the results in a bar plot with the explained variance on the y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "features = echo_tracks.drop(['genre_top', 'title', 'track_id'], axis=1) \n",
    "labels = echo_tracks['genre_top']\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(features)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "x = range(len(pca.explained_variance_))\n",
    "y = pca.explained_variance_ratio_\n",
    "ax.bar(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Compare the predictive power of logistic regression and a decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> After using PCA to visualize and qualitatively inspect the data, it is now time to make quantitative predictions about the genres of the missing songs. There are many algorithms that could perform well on this type of task. Here, we will try a few common algorithms.\n",
    "\n",
    "> The first algorithm will be a decision tree. We'll start by splitting the data into training and test sets, and then train a decision tree classifier on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(\n",
    "    features, labels, random_state=10)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier(random_state=10)\n",
    "tree.fit(train_features, train_labels)\n",
    "tree.score(test_features, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Stop here! Only the three first tasks :)*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
